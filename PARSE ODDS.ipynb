{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "import numpy as np\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import copy\n",
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запускать только с включенным VPN, иначе не отображаются некоторые года"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = webdriver.Chrome(\"/Users/yasha_ten/Downloads/chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.oddsportal.com/results/#tennis'\n",
    "web.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "tournaments = web.find_element_by_css_selector('tbody').find_elements_by_css_selector(\"tr\")\n",
    "for tourn in tournaments:\n",
    "    for name in tourn.find_elements_by_css_selector(\"td\"):\n",
    "        name = name.text\n",
    "        if name == 'ATP Next Gen Finals - Milan':\n",
    "            break\n",
    "        if 'ATP' in name and 'Challenger' not in name and 'Doubles' not in name and\\\n",
    "        'Davis' not in name and 'Olympic' not in name and 'Laver' not in name and 'Next Gen' not in name:\n",
    "            names.append(name)\n",
    "names.pop(names.index(\"ATP ATP Cup\"))\n",
    "names.pop(names.index(\"ATP Cup Teams - Men\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find links for tournaments\n",
    "links = []\n",
    "for name in names:\n",
    "    link = web.find_element_by_link_text(name).get_attribute('href')\n",
    "    links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_time(df):\n",
    "    time = []\n",
    "    date_fx = []\n",
    "    months = {\"Jan\": 1, \"Feb\": 2, \"Mar\": 3,\n",
    "              \"Apr\": 4, \"May\": 5, \"Jun\": 6,\n",
    "              \"Jul\": 7, \"Aug\": 8, \"Sep\": 9,\n",
    "              \"Oct\": 10, \"Nov\": 11, \"Dec\": 12\n",
    "             }\n",
    "    for date in df[\"date\"]:\n",
    "        mas = date.split()\n",
    "        date_fx.append(datetime.date(int(mas[2][:-1]), months[mas[1]], int(mas[0])))\n",
    "        podmas = mas[-1].split(\":\")\n",
    "        time.append(datetime.time(int(podmas[0]), int(podmas[1]), 0))\n",
    "    df[\"time\"] = time\n",
    "    df[\"date\"] = date_fx\n",
    "    \n",
    "def fix_letters(df_):\n",
    "    progress = IntProgress(min=0, max=len(df_), value=0)\n",
    "    display(progress)\n",
    "    bug_surnames = {'Hüsler M.': 'Huesler M.', 'Mcdonald M.': 'McDonald M.',\n",
    "                    'del Potro J.': 'Del Potro J.', 'López-Pérez E.': 'Lopez-Perez E.',\n",
    "                   'Di Wu.': 'Wu D.', 'Yen-Hsun Lu.': 'Lu Y.H.', 'Mcgee J.': 'McGee J.',\n",
    "                   'Zhe Li.': 'Li Z.', 'Wolf J.J.': 'Wolf J.', 'Bautista Agut R.': 'Bautista-Agut R.',\n",
    "                   'Ramos-Viñolas A.': 'Ramos A.', 'Carreño Busta P.': 'Carreno-Busta P.', 'Struff J.': 'Struff J-L.',\n",
    "                   'Tsonga J.': 'Tsonga J-W.', 'de Minaur A.': 'De Minaur A.', 'Andújar P.': 'Andujar-Alba P.',\n",
    "                    'Dutra Silva R.': 'Dutra Da Silva D.', 'Smith J.': 'Smith J. P.', 'Estrella Burgos V.': 'Estrella V.',\n",
    "                    'Popyrin A.': 'Popyrin Al.', 'Londero J.': 'Londero J. I.', 'Harris L.': 'Harris G.',\n",
    "                    'de Bakker T.': 'De Bakker T.', 'Kwon S.': 'Kwon Soonwoo', 'Galán D.': 'Galan Riveros D. E.',\n",
    "                    'Lee D.': 'Lee D. H.', 'Muñoz de la Nava D.': 'Munoz-De La Nava D.', 'Ojeda Lara R.': 'Ojeda L. R.',\n",
    "                    'Kuznetsov A.': 'Kuznetsov Al.', 'Lindell C.': 'Lindell Ch.', 'Vilella Martínez M.': 'Vilella M. M.',\n",
    "                    'Kwiatkowski T.': 'Kwiatkowski T. S.', 'Moroni G.': 'Moroni M.',\n",
    "                    'Huta Galung J.': 'Huta-Galung J.', 'Mukund S.': 'Mukund S. K.', 'Ramirez Hidalgo R.': 'Ramirez-H.R.',\n",
    "                    'Tyurnev E.': 'Tiurnev E.', 'Yecong He.': 'He Y.', 'Statham R.': 'Statham J. R.',\n",
    "                   'Rigele Te.': 'Te R.', 'Prashanth N.': 'Prashanth V.', 'Yibing W.': 'Wu Y.',\n",
    "                    'Varillas J.': 'Varillas J. P.', 'Ficovich J.': 'Ficovich J. P.', 'Lipovšek Puches T.': 'Lipovsek P. T.',\n",
    "                    'Tatlot J.': 'Tatlot J. S.', 'Sorgi J.': 'Sorgi J. P.', 'Zayed M.': 'Zayed M. S.'}\n",
    "    letters = {'á': 'a', 'ã': 'a', 'ç': 'c',\n",
    "           'é': 'e', 'í': 'i', 'ñ': 'n',\n",
    "           'ó': 'o', 'ö': 'o', 'ú': 'u',\n",
    "          'ü': 'u', 'ý': 'y', 'ć': 'c',\n",
    "          'č': 'c', 'ě': 'e', 'ı': 'i',\n",
    "          'ł': 'l', 'ř': 'r', 'š': 's',\n",
    "          'ž': 'z'}\n",
    "    for i in range(len(df_)):\n",
    "        p1 = df_['player1'][i]\n",
    "        p2 = df_['player2'][i]\n",
    "        p2.replace('\\n', '') ## лишние \\n при парсинге oddsportal\n",
    "        \n",
    "        if p1 in bug_surnames:\n",
    "            p1 = bug_surnames[p1]\n",
    "            \n",
    "        if p2 in bug_surnames:\n",
    "            p2 = bug_surnames[p2]\n",
    "\n",
    "        for c in range(len(p1)):\n",
    "            if p1[c].lower() in letters:\n",
    "                if p1[c].islower():\n",
    "                    p1 = p1.replace(p1[c], letters[p1[c]])\n",
    "                else:\n",
    "                    p1 = p1.replace(p1[c], letters[p1[c].lower()].upper())\n",
    "\n",
    "        for c in range(len(p2)):\n",
    "            if p2[c].lower() in letters:\n",
    "                if p2[c].islower():\n",
    "                    p2 = p2.replace(p2[c], letters[p2[c]])                    \n",
    "                else:\n",
    "                    p2 = p2.replace(p2[c], letters[p2[c].lower()].upper())\n",
    "\n",
    "        df_['player1'][i] = p1\n",
    "        df_['player2'][i] = p2\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            progress.value = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_arr(arr, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(arr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# читаем из файла\n",
    "def read_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        arr = json.load(f)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_until_cond_css(css):\n",
    "        flag = 0\n",
    "        while True:\n",
    "            try:\n",
    "                web.find_element_by_css_selector(css)\n",
    "                break\n",
    "            except Exception:\n",
    "                if (flag < 20):\n",
    "                    sleep(0.5)\n",
    "                    flag += 1\n",
    "                else:\n",
    "                    raise NoSuchElementException\n",
    "                    \n",
    "def wait_until_cond_link(link):\n",
    "        flag = 0\n",
    "        while True:\n",
    "            try:\n",
    "                web.find_element_by_link_text(link)\n",
    "                break\n",
    "            except Exception:\n",
    "                if (flag < 20):\n",
    "                    sleep(0.5)\n",
    "                    flag += 1\n",
    "                else:\n",
    "                    raise NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_arr(names, \"tourn_names.txt\")\n",
    "write_arr(links, \"tourn_links.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = read_file('tourn_names.txt')\n",
    "links = read_file('tourn_links.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_matches(matches, urls_):\n",
    "    i = 0\n",
    "    for match in matches:\n",
    "        names_ = match.split(' - ')\n",
    "        p1 = names_[0]\n",
    "        p2 = names_[1]\n",
    "        web.get(urls_[i])\n",
    "        sleep(0.25)\n",
    "#             wait_until_cond_link(match)\n",
    "#             web.find_element_by_link_text(match).click()\n",
    "# #             act = ActionChains(web)\n",
    "# #             act.click(el_).perform()\n",
    "        \n",
    "    \n",
    "        if web.find_elements_by_css_selector('center') != []:\n",
    "            web.refresh()\n",
    "            sleep(3)\n",
    "            \n",
    "        wait_until_cond_css(\"p.date.datet\")\n",
    "        date = web.find_element_by_css_selector(\"p.date.datet\").text.split(',')[1].split()\n",
    "        date = datetime.date(int(date[2]), months[date[1]], int(date[0])) ## match date\n",
    "\n",
    "        coefs = web.find_elements_by_css_selector(\"tr.lo.odd\") ## find coefs odd_\n",
    "        elem = {'player1': p1, 'player2': p2, 'date': date}\n",
    "        for bm in coefs:\n",
    "            bm = bm.text.split()\n",
    "            name = bm[0] ## аккуратно в следующий раз, переделать, если имя состоит из нескольких слов, то идет съезд...\n",
    "            k1 = bm[1]\n",
    "            k2 = bm[2]\n",
    "            ## add koefs to match\n",
    "            elem['k1_' + name] = k1\n",
    "            elem['k2_' + name] = k2\n",
    "\n",
    "        coefs = web.find_elements_by_css_selector(\"tr.lo.even\") ## find coefs even_\n",
    "        for bm in coefs:\n",
    "            bm = bm.text.split()\n",
    "            name = bm[0] ## аккуратно в следующий раз, переделать, если имя состоит из нескольких слов, то идет съезд...\n",
    "            k1 = bm[1]\n",
    "            k2 = bm[2]\n",
    "            ## add koefs to match\n",
    "            elem['k1_' + name] = k1\n",
    "            elem['k2_' + name] = k2\n",
    "        try:\n",
    "            a = web.find_elements_by_css_selector('td.center.disabled')[0].text.split()[0]\n",
    "            b = web.find_elements_by_css_selector('td.center.disabled')[1].text.split()[0]\n",
    "            user1 = round(100 / int(a.replace('%', '')), 2)\n",
    "            user2 = round(100 / int(b.replace('%', '')), 2)\n",
    "            elem['k1_user'] = user1\n",
    "            elem['k2_user'] = user2\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        data.append(elem) ## add match to array\n",
    "        i += 1\n",
    "\n",
    "months = {\"Jan\": 1, \"Feb\": 2, \"Mar\": 3,\n",
    "              \"Apr\": 4, \"May\": 5, \"Jun\": 6,\n",
    "              \"Jul\": 7, \"Aug\": 8, \"Sep\": 9,\n",
    "              \"Oct\": 10, \"Nov\": 11, \"Dec\": 12\n",
    "            }\n",
    "\n",
    "for link in links:\n",
    "    web.get(link) ## go to tournament page\n",
    "    sleep(3)\n",
    "    if web.find_element_by_css_selector('div#breadcrumb').text != 'The page you requested is not available.':\n",
    "        years = {}\n",
    "        wait_until_cond_css('div.main-menu2.main-menu-gray')\n",
    "\n",
    "        ## find all needed years\n",
    "        years = {}\n",
    "        for x in web.find_element_by_css_selector('div.main-menu2.main-menu-gray').find_elements_by_css_selector('li'):\n",
    "            years[int(x.find_element_by_css_selector('a').text)] = x.find_element_by_css_selector('a').get_attribute('href')\n",
    "\n",
    "        for year in range(2015, 2021):\n",
    "            matches = []\n",
    "            if year in years:\n",
    "    #             print(\"Go to \", year)\n",
    "    #             print(years[year])\n",
    "                web.get(years[year]) ## go to needed year\n",
    "                sleep(1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            sleep(1.5)\n",
    "            pagination = web.find_elements_by_css_selector('div#pagination')\n",
    "\n",
    "            if pagination != []: ## condition to check whether pages\n",
    "                page_links = set()\n",
    "                for x in pagination[0].find_elements_by_css_selector('a'):\n",
    "                    page_links.add(x.get_attribute('href'))\n",
    "\n",
    "                for link_ in page_links:\n",
    "                    matches.clear()\n",
    "                    urls_.clear()\n",
    "                    web.get(link_) ## change page\n",
    "                    wait_until_cond_css('td.name.table-participant')\n",
    "                    sleep(2)\n",
    "                    for match in web.find_elements_by_css_selector('td.name.table-participant'): ## add matches on page\n",
    "                        matches.append(match.text)\n",
    "                    ## links of this mathces\n",
    "                    urls_ = [x.find_element_by_css_selector('a').get_attribute('href') for x in web.find_elements_by_css_selector('td.name.table-participant')]\n",
    "                    ## parse every match by link\n",
    "                    parse_matches(matches, urls_)\n",
    "\n",
    "            else:\n",
    "                for match in web.find_elements_by_css_selector('td.name.table-participant'):\n",
    "                    matches.append(match.text)\n",
    "\n",
    "                urls_ = [x.find_element_by_css_selector('a').get_attribute('href') for x in web.find_elements_by_css_selector('td.name.table-participant')]\n",
    "                parse_matches(matches, urls_)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data).set_index(['date', 'player1', 'player2']).sort_index()\n",
    "df.to_pickle('all_odds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('all_odds.pkl')\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.drop(['k1_Asianodds', 'k2_Asianodds', 'k1_GGBET', 'k2_GGBET', 'k1_William', 'k2_William'], axis=1)\n",
    "\n",
    "set_ = drop_n_fill_trash(df)\n",
    "## del trash\n",
    "for ind in set_:\n",
    "    df = df.drop(ind)\n",
    "df = df.set_index('player1').reset_index()\n",
    "## combine coefs and data\n",
    "combine(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37282b3b89d545fa94f439cf42649ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=22094)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ = pd.read_pickle('matches.pkl')\n",
    "fix_time(df_)\n",
    "df_ = df_[df_['date'] > np.datetime64('2015-01-01')].set_index('player1').reset_index()\n",
    "fix_letters(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_pickle('all_coefs_combine.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1_1xBet :  150\n",
      "k1_bet-at-home :  304\n",
      "k1_Betsafe :  483\n",
      "k1_bwin :  1646\n",
      "k1_Marathonbet :  408\n",
      "k1_Unibet :  1901\n",
      "k1_888sport :  1470\n",
      "k1_bet365 :  86\n",
      "k1_Betway :  561\n",
      "k1_bwin.fr :  10692\n",
      "k1_Pinnacle :  142\n",
      "k1_user :  2769\n",
      "k1_BetWorld :  6617\n",
      "k1_Bethard :  9465\n",
      "k1_Coolbet :  10049\n"
     ]
    }
   ],
   "source": [
    "## bm : missed missings\n",
    "for k in df.keys():\n",
    "    if 'k1' in k:\n",
    "        print(k, ': ', len(df) - len(df.dropna(subset=[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
